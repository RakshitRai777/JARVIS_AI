# JARVIS_AI ğŸ§ âœ¨

A lightweight, multimodal AI assistant inspired by Iron Manâ€™s JARVIS.  
This project integrates cutting-edge open-source models to provide text, image, and voice-based interactions â€” all running locally without dependency on external APIs.

---

## ğŸš€ Features
- **Voice Activation**: Wake-word detection for hands-free use.
- **Multimodal Input/Output**: Supports text, speech, and image generation.
- **Local Deployment**: CPU-only optimized workflows, no GPU/API required.
- **Prompt Benchmarking**: Comprehensive suite to test fidelity, adherence, and edit consistency.
- **Customizable Personality**: Context-aware responses with personality-driven interactions.

---

## ğŸ› ï¸ Tech Stack
- **Python 3.9+**
- **Groq / GPT-OSS-120B / LLaMA** (text models)
- **Stable Diffusion / Stable Video Diffusion** (media generation)
- **SpeechRecognition + PyAudio** (voice input)
- **Flask / FastAPI** (web interface)
- **Git LFS** (for large model files)

---

## ğŸ“¦ Installation
Clone the repository and set up dependencies:

```bash
git clone https://github.com/RakshitRai777/JARVIS_AI.git
cd JARVIS_AI
pip install -r requirements.txt

---

â–¶ï¸ Usage
Run the assistant locally:
python jarvis.py

Say the wake word to activate voice mode.

Use the CLI or web interface for text/image queries.

Outputs are generated in real time.

---

ğŸ“œ License
This project is licensed under the MIT License â€” see the LICENSE file for details.

---

ğŸ’¡ Inspiration
Inspired by cinematic AI systems like JARVIS, this project aims to replicate natural, hands-free, and creative interaction with modern AI models.
